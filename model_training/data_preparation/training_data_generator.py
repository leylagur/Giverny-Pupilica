import json
import random
from typing import List, Dict, Any

class TrainingDataGenerator:
    def __init__(self):
        self.ranking_ranges = [
            (50000, 150000),   # YÃ¼ksek performans hedefleyenler
            (150000, 300000),  # Orta-Ã¼st performans
            (300000, 500000),  # Orta performans
            (500000, 700000),  # Orta-alt performans
            (700000, 1000000), # DÃ¼ÅŸÃ¼k performans
        ]
        
        # Ä°lgi alanÄ± Ã§eÅŸitlendirmesi iÃ§in alternatif ifadeler
        self.interest_variations = {
            'teknoloji': ['teknoloji', 'bilgisayar', 'yazÄ±lÄ±m', 'dijital teknoloji', 'IT'],
            'saÄŸlÄ±k': ['saÄŸlÄ±k', 'tÄ±p', 'hasta bakÄ±mÄ±', 'saÄŸlÄ±k hizmetleri', 'medikal'],
            'sanat': ['sanat', 'tasarÄ±m', 'yaratÄ±cÄ±lÄ±k', 'estetik', 'gÃ¶rsel sanatlar'],
            'matematik': ['matematik', 'hesaplama', 'sayÄ±sal analiz', 'matematiksel dÃ¼ÅŸÃ¼nce'],
            'iletiÅŸim': ['iletiÅŸim', 'sosyal beceiler', 'insan iliÅŸkileri', 'medya'],
            'spor': ['spor', 'fiziksel aktivite', 'atletizm', 'fitness'],
            'doÄŸa': ['doÄŸa', 'Ã§evre', 'tarÄ±m', 'ekoloji', 'yeÅŸil teknoloji'],
            'gÃ¼venlik': ['gÃ¼venlik', 'koruma', 'emniyet', 'kurtarma operasyonlarÄ±'],
            'iÅŸletme': ['iÅŸletme', 'yÃ¶netim', 'ekonomi', 'ticaret', 'giriÅŸimcilik'],
            'mÃ¼hendislik': ['mÃ¼hendislik', 'teknik bilim', 'proje yÃ¶netimi', 'sistem tasarÄ±mÄ±']
        }

    def load_extracted_data(self, file_path: str) -> List[Dict]:
        """Keyword extractor'dan Ã§Ä±kan veriyi yÃ¼kle"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def generate_interest_variations(self, interests: List[str]) -> List[str]:
        """Ä°lgi alanlarÄ±nÄ± farklÄ± ÅŸekillerde ifade et"""
        varied_interests = []
        for interest in interests:
            if interest in self.interest_variations:
                variations = self.interest_variations[interest]
                varied_interests.append(random.choice(variations))
            else:
                varied_interests.append(interest)
        return varied_interests

    def is_ranking_match(self, dept_ranking: str, target_min: int, target_max: int) -> bool:
        """BÃ¶lÃ¼m sÄ±ralamasÄ± hedef aralÄ±kta mÄ± kontrol et"""
        try:
            ranking = float(str(dept_ranking).replace(',', '.'))
            return target_min <= ranking <= target_max
        except (ValueError, TypeError):
            return False

    def create_training_sample(self, department: Dict, target_range: tuple) -> Dict:
        """Tek bir training sample oluÅŸtur"""
        target_min, target_max = target_range
        
        # Ä°lgi alanlarÄ±nÄ± Ã§eÅŸitlendir
        varied_interests = self.generate_interest_variations(department['interests'])
        
        # Hedef sÄ±ralamanÄ±n ortasÄ±nÄ± al
        target_ranking = (target_min + target_max) // 2
        
        # Input oluÅŸtur
        interests_str = ', '.join(varied_interests)
        input_text = f"Ä°lgi alanlarÄ±m: {interests_str}. YKS sÄ±ralamasÄ±: {target_ranking}"
        
        # Output oluÅŸtur
        ranking = department['ranking_2025']
        output_text = f"{department['bolum_adi']} - {department['universite']} (SÄ±ralama: {ranking})"
        
        return {
            "input": input_text,
            "output": output_text,
            "metadata": {
                "department": department['bolum_adi'],
                "university": department['universite'],
                "city": department['sehir'],
                "actual_ranking": ranking,
                "target_range": f"{target_min}-{target_max}",
                "interests": department['interests']
            }
        }

    def generate_training_data(self, extracted_data: List[Dict]) -> List[Dict]:
        """Ana training data generation fonksiyonu"""
        training_samples = []
        
        for target_range in self.ranking_ranges:
            target_min, target_max = target_range
            
            # Bu sÄ±ralama aralÄ±ÄŸÄ±na uyan bÃ¶lÃ¼mleri bul
            matching_departments = [
                dept for dept in extracted_data 
                if self.is_ranking_match(dept['ranking_2025'], target_min, target_max)
                and dept['interests']  # Ä°lgi alanÄ± boÅŸ olmayanlar
            ]
            
            print(f"SÄ±ralama aralÄ±ÄŸÄ± {target_min}-{target_max}: {len(matching_departments)} bÃ¶lÃ¼m")
            
            # Her uygun bÃ¶lÃ¼m iÃ§in training sample oluÅŸtur
            for dept in matching_departments:
                # Her bÃ¶lÃ¼m iÃ§in 2-3 farklÄ± varyasyon oluÅŸtur
                for _ in range(random.randint(2, 3)):
                    sample = self.create_training_sample(dept, target_range)
                    training_samples.append(sample)
        
        # Training data'yÄ± karÄ±ÅŸtÄ±r
        random.shuffle(training_samples)
        return training_samples

    def create_validation_data(self, training_data: List[Dict], split_ratio: float = 0.2) -> tuple:
        """Training ve validation setlerini ayÄ±r"""
    
        # Stratified split yaparak her label'dan hem train hem val'de bulunmasÄ±nÄ± saÄŸla
        from collections import defaultdict
    
        # Label'lara gÃ¶re grupla
        label_groups = defaultdict(list)
        for item in training_data:
            label_groups[item['output']].append(item)
    
        train_data = []
        val_data = []
    
        # Her label'dan en az 1 tane train'de kalsÄ±n
        for label, items in label_groups.items():
            if len(items) == 1:
                train_data.extend(items)  # Tek Ã¶rnek varsa train'e koy
            else:
                split_idx = max(1, int(len(items) * (1 - split_ratio)))
                train_data.extend(items[:split_idx])
                val_data.extend(items[split_idx:])
    
        return train_data, val_data

    def save_training_data(self, training_data: List[Dict], output_path: str):
        """Training data'yÄ± kaydet"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(training_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Training data saved: {output_path}")
        print(f"ğŸ“Š Total samples: {len(training_data)}")

    def generate_statistics(self, training_data: List[Dict]):
        """Training data istatistiklerini gÃ¶ster"""
        print("\nğŸ“ˆ TRAINING DATA Ä°STATÄ°STÄ°KLERÄ°:")
        print(f"Toplam sample sayÄ±sÄ±: {len(training_data)}")
        
        # SÄ±ralama aralÄ±klarÄ±na gÃ¶re daÄŸÄ±lÄ±m
        range_distribution = {}
        for sample in training_data:
            target_range = sample['metadata']['target_range']
            range_distribution[target_range] = range_distribution.get(target_range, 0) + 1
        
        print("\nğŸ¯ SÄ±ralama AralÄ±ÄŸÄ± DaÄŸÄ±lÄ±mÄ±:")
        for range_key, count in sorted(range_distribution.items()):
            print(f"  {range_key}: {count} samples")
        
        # Ä°lgi alanÄ± daÄŸÄ±lÄ±mÄ±
        interest_count = {}
        for sample in training_data:
            for interest in sample['metadata']['interests']:
                interest_count[interest] = interest_count.get(interest, 0) + 1
        
        print("\nğŸ¨ Ä°lgi AlanÄ± DaÄŸÄ±lÄ±mÄ±:")
        for interest, count in sorted(interest_count.items(), key=lambda x: x[1], reverse=True):
            print(f"  {interest}: {count} samples")

    def show_sample_examples(self, training_data: List[Dict], num_examples: int = 5):
        """Ã–rnek training sample'larÄ±nÄ± gÃ¶ster"""
        print(f"\nğŸ“‹ Ã–RNEK TRAINING SAMPLES ({num_examples} adet):")
        
        for i, sample in enumerate(training_data[:num_examples]):
            print(f"\n{i+1}. SAMPLE:")
            print(f"   INPUT:  {sample['input']}")
            print(f"   OUTPUT: {sample['output']}")

def main():
    generator = TrainingDataGenerator()
    
    # Keyword extractor'dan veriyi yÃ¼kle
    print("ğŸ“‚ Extracted keywords loading...")
    extracted_data = generator.load_extracted_data('/Users/ardaerdegirmenci/Desktop/Pupilica/giverny/Dataset_creation/Datasets/extracted_keywords.json')
    print(f"âœ… {len(extracted_data)} bÃ¶lÃ¼m yÃ¼klendi")
    
    # Training data oluÅŸtur
    print("\nğŸ¤– Training data generation baÅŸlÄ±yor...")
    training_data = generator.generate_training_data(extracted_data)
    
    # Train/validation split
    train_data, val_data = generator.create_validation_data(training_data)
    
    # DosyalarÄ± kaydet
    generator.save_training_data(train_data, '/Users/ardaerdegirmenci/Desktop/Pupilica/giverny/model_training/model_datasets/train_data.json')
    generator.save_training_data(val_data, '/Users/ardaerdegirmenci/Desktop/Pupilica/giverny/model_training/model_datasets/val_data.json')
    generator.save_training_data(training_data, '/Users/ardaerdegirmenci/Desktop/Pupilica/giverny/model_training/model_datasets/ful_training_data.json')
    
    # Ä°statistikler ve Ã¶rnekler
    generator.generate_statistics(training_data)
    generator.show_sample_examples(training_data)
    
    print(f"\nğŸ‰ Training data generation tamamlandÄ±!")
    print(f"ğŸ“Š Train samples: {len(train_data)}")
    print(f"ğŸ“Š Validation samples: {len(val_data)}")

if __name__ == "__main__":
    main()